var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ScalingCollapse","category":"page"},{"location":"#ScalingCollapse","page":"Home","title":"ScalingCollapse","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ScalingCollapse.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [ScalingCollapse]","category":"page"},{"location":"#ScalingCollapse.Data","page":"Home","title":"ScalingCollapse.Data","text":"Data(L::Int, xs::Vector{Float64}, ys::Vector{Float64}, es::Vector{Float64})\n\nA Data object stores the data for a single system size. Sorted by the x values.\n\nFields\n\nL::Int: system size\nxs::Vector{Float64}: x values\nys::Vector{Float64}: y values\nes::Vector{Float64}: y error values\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.Houdayer","page":"Home","title":"ScalingCollapse.Houdayer","text":"Houdayer()\n\nQuality function that uses the Houdayer & Hartmann method to calculate the quality of a scaling. It is less stable than the spline methods and the Linear method and therefore not recommended.\n\nHow does it work?\n\nTO BE DOCUMENTED\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.Linear","page":"Home","title":"ScalingCollapse.Linear","text":"Linear()\n\nQuality function that interpolates all scaled data points to a single master curve. For every data point, we take the closest data points, to the left and to the right to interpolate a linear function. The quality is then calculated as the sum of the squared differences between the data points and the interpolated values.\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.MultipleSplines","page":"Home","title":"ScalingCollapse.MultipleSplines","text":"MultipleSplines(; N_steps::Int=100, weight_density::Bool=true)\n\nQuality function that uses a spline interpolation to calculate the quality of a scaling.\n\nHow does it work?\n\nTO BE DOCUMENTED\n\nKeyword arguments\n\nN_steps::Int=100: Number of points used in the interval to calculate the quality.\nweight_density::Bool=true: If true, the quality is weighted by the density of data points in the interval.\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.ScalingFunction","page":"Home","title":"ScalingCollapse.ScalingFunction","text":"ScalingFunction(preset::Symbol; kwargs...)\nScalingFunction(f::Function; kwargs...)\n\nA ScalingFunction is used in a ScalingProblem to rescale the data. It is defined by a function f and a set of parameters p_names. The function f is called with the data d and the parameters p1, p2, ... and returns a new Data object.\n\nArguments\n\npreset::Symbol: a preset for the ScalingFunction. See Presets below.\nf::Function: the function f to be used in the ScalingFunction. Pass this   argument to create a custom ScalingFunction. f should take a Data object   and a set of parameters p1, p2, ... and return a new Data object:   f(d::Data, p1, p2, ...) -> Data.\nNote that you might want to set the function f as a keyword argument to   use the \"fixing parameters\" feature (see below).\n\nPresets\n\nThe preset argument can be used to create a ScalingFunction with a preset function f and a preset set of parameter names p_names. The following presets are available:\n\n:x rescale the x values of the data according to x -> (x - p1)/p1 * L^(1/p2)\n:xy rescale the x and y values of the data according to x -> (x - p1)/p1 * L^(1/p2)   and y -> y * L^(p3/p2)\n:xny rescale the x and y values of the data according to x -> (x - p1)/p1 * L^(1/p2)   and y -> y * L^(-p3/p2)\n\nKeyword arguments\n\np_names::Vector{String}: the parameter names p_names to be used in the   ScalingFunction. This kwarg can be used to overwrite the preset parameter   names p_names (p1, p2, ...).\nf::Function: the function f to be used in the ScalingFunction. This kwarg can   be used to overwrite the preset function f. If you pass f as a kwarg, instead of   an argument, you can use the \"fixing parameters\" feature (see below). In that case   the number of paramters of your function f should match the preset, i.e. if your   function f takes 2 parameters, you should use the preset :x and if your function   f takes 3 parameters, you should use the preset :xy.\nx_scale::String: the scaling function for the x values. This is just used to   display the scaling function in plots and julias show function.\ny_scale::String: the scaling function for the y values. This is just used to   display the scaling function in plots and julias show function.\np::Float64: fix a parameter to a value. If you know the analytical value of a scaling   parameter you might want to fix it to this value. This can speed up the optimization   and give better results. Note, that p is either \"p1\", \"p2\", ... or the name you   specified in p_names.\nNote that this feature is only available if you use one of the presets. You can still   modify the scaling function by setting f as a kwarg.\n\nExamples\n\nPresets\n\n# rescale the x axis only\nScalingFunction(:x; p_names=[\"T_c\", \"nu\"])\n\n# lets fix nu to 1.0\nScalingFunction(:x; p_names=[\"T_c\", \"nu\"], nu=1.0)\n\n# rescale the x and y axis\nScalingFunction(:xy; p_names=[\"T_c\", \"nu\", \"beta\"])\n\n# rescale the x and y axis with negative exponent on y\nScalingFunction(:xny; p_names=[\"T_c\", \"nu\", \"gamma\"])\n\nCustom scaling function\n\n# define the function that scales the data\nfunction myfunction(d::ScalingCollapse.Data, p1, p2)\n\n    #  initialize arrays for scaled data\n    xs = zeros(length(d.xs))\n    ys = zeros(length(d.ys))\n    es = zeros(length(d.es))\n\n    # scale data according to p1 and p2\n    for (i, x, y, e) in zip(eachindex(d.xs), d.xs, d.ys, d.es)\n        xs[i] = (x - p1) / p1 * log(d.L)\n        ys[i] = y * d.L^(p2)\n        es[i] = e * d.L^(p2)\n    end\n\n    # create new Data object with scaled data\n    return ScalingCollapse.Data(d.L, xs, ys, es)\nend\n\nScalingFunction(myfunction; p_names=[\"myp1\", \"myp2\"])\n\n# lets say we want to fix the parameter \"myp1\" to 1.0\n# we use the preset :x (because it also has 2 parameters) and overwrite the function f\nScalingFunction(:x; f=myfunction, p_names=[\"myp1\", \"myp2\"], myp1=1.0)\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.ScalingProblem","page":"Home","title":"ScalingCollapse.ScalingProblem","text":"ScalingProblem(args...; kwargs...)\n\nCreate a scaling problem which solves on initialization.\n\nArguments\n\nxs: x values of the data\nys: y values of the data\nes: y error values of the data (optional)\nLs: system sizes of the data\n\nFor more information on the arguments, see methods(ScalingCollapse.unzip_data).\n\nKeyword Arguments\n\nsf::ScalingFunction=ScalingFunction(preset; kwargs...): scaling function\np_space::Vector{StepRangeLen}=[0.1:0.1:3.0 for _ in sf.p_names]: parameter search space\ndx::Vector{Float64}=[-Inf, Inf]: optimization interval\nquality::QualityFunction=Linear(): quality function\nquality_scan::QualityFunction=MultipleSplines(scan_mode=true): quality function for the   parameter space scan (it is highly recommended to use the default function here)\nverbose::Bool=false: print information during optimization\nstarting_ps::Vector{Float64}: If starting_ps are given, there will be no initial   parameter space scan. Instead, the optimization will start at the given points. This is   much faster, but might not find the global minimum.\nerror::Bool=true: If error=true, the error analysis will be performed to give   estimates of the uncertainties of the optimal parameters.\n\nFields\n\ndata::Vector{Data}: data to be scaled\nsf::ScalingFunction: scaling function\np_space::Vector{StepRangeLen}: search parameter space\ndx::Vector{Float64}: optimization interval\noptimal_ps::Vector{Float64}: optimal parameters\noptimal_ps_error::Vector{Float64}: uncertainties of the optimal parameters\nminimum::Float64: minimum of the objective function\nsolved::Bool: true if optimization was called\nverbose::Bool: print information during optimization\nerror::Bool: perform error analysis\nquality_scan::QualityFunction: quality function for the parameter space scan\nquality::QualityFunction: quality function\nskip_scan::Bool: true if starting_ps are given by the user\nstarting_ps::Vector{Float64}: starting points for the optimization\nerrors_defined::Bool: true if errors are given by the user\n\nExamples\n\nusing ScalingCollapse\n\nrescale the x axis only\n\n# (e.g. for ys == binder cumulant of Ising model)\nScalingProblem(xs, ys, Ls;\n    sc=ScalingFunction(:x; p_names=[\"T_c\", \"nu\"]),\n    p_space=[0.1:0.1:3.0, 0.1:0.1:3.0],\n    dx=[-1.0, 1.0],\n)\n\n# or the same but with errors\nScalingProblem(xs, ys, es, Ls;\n    sc=ScalingFunction(:x; p_names=[\"T_c\", \"nu\"]),\n    p_space=[0.1:0.1:3.0, 0.1:0.1:3.0],\n    dx=[-1.0, 1.0],\n)\n\nrescale the x and y axis\n\n# (e.g. for ys == magnetization of Ising model)\nScalingProblem(xs, ys, Ls;\n    sc=ScalingFunction(:xy; p_names=[\"T_c\", \"nu\", \"beta\"]),\n    dx=[-1.0, 1.0],\n)\n\nrescale the x and y axis, but y axis with negative exponent\n\n# (e.g. for ys == susceptibility of Ising model)\nScalingProblem(xs, ys, Ls;\n    sc=ScalingFunction(:xny; p_names=[\"T_c\", \"nu\", \"gamma\"]),\n    dx=[-1.0, 1.0],\n)\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.SingleSpline","page":"Home","title":"ScalingCollapse.SingleSpline","text":"SingleSpline()\n\nQuality function that interpolates all scaled data points to a single spline. The quality is then calculated as the sum of the squared differences between the data points and the interpolated values. The spline is fitted using the KissSmoothing.jl package. The number of knots can be specified using the N_knots keyword argument. If N_knots is not specified, the number of knots is set to total_number_of_data_points / 10.\n\n\n\n\n\n","category":"type"},{"location":"#ScalingCollapse.residuals-Tuple{Any}","page":"Home","title":"ScalingCollapse.residuals","text":"residuals(sp; kwargs...)\n\nCalculate the residuals of the ScalingProblem around the optimal parameters or for a given parameter space.\n\nArguments\n\nsp::ScalingProblem: The ScalingProblem to calculate the residuals for.\n\nKeyword Arguments\n\np_space::Vector{Vector{Float64}}: The parameter space to calculate the residuals for.   If not provided, the parameter space is calculated from the optimal parameters,   their errors and the number of steps.\nN_steps::Int=50: The number of steps to use for the default parameter space.\ndims::Vector{Int}=[1, ...]: The dimensions to calculate the residuals for. If not   specified, all dimensions are used.\n\nReturns\n\np_space::Vector{StepRangeLen}: The parameter space used for the calculation.\nresiduals::Array{Float64}: The residuals for the given parameter space.\n\nExample\n\n# lets say our xs, ys and Ls are data for the susceptibility of the Ising model\nusing ScalingCollapse\nsp = ScalingProblem(xs, ys, Ls;\n    sc=ScalingFunction(:xny; p_names=[\"T_c\", \"nu\", \"gamma\"]),\n    dx=[-1.0, 2.0],\n)\n\n# now we can calculate the residual landscape around the optimal parameters as follows:\np_space, residuals = residuals(sp)\n# in the above case length(p_space) == 3 and size(residuals) == (50, 50, 50)\n\n# we can specify the dimensions we are interested in as follows:\np_space, residuals = residuals(sp; dims=[1, 2])\n# now length(p_space) == 2 and size(residuals) == (50, 50)\n# we fixed the third parameter (in this case gamma) to its optimal value and calculated\n# a 2D cut through the 3D residual landscape\n\n\n\n\n\n","category":"method"},{"location":"#ScalingCollapse.scaled_data-Tuple{ScalingProblem}","page":"Home","title":"ScalingCollapse.scaled_data","text":"scaled_data(sp::ScalingProblem)\nscaled_data(sp::ScalingProblem, ps)\n\nReturn the scaled data of the ScalingProblem sp.\n\nArguments\n\nsp::ScalingProblem: scaling problem\nps::Vector{Float64}=sp.optimal_ps: parameters to scale the data with (manually)\n\nReturns\n\nxs::Vector{Vector{Float64}}: scaled x values\nys::Vector{Vector{Float64}}: scaled y values\nes::Vector{Vector{Float64}}: scaled y error values\nLs::Vector{Float64}: scaled system sizes\n\n\n\n\n\n","category":"method"}]
}
